{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from scipy import misc\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import facenet\n",
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "from tensorflow.python.training import training\n",
    "import random\n",
    "import re\n",
    "from tensorflow.python.platform import gfile\n",
    "from six import string_types, iteritems\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers={\"User-Agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Mobile Safari/537.36\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import pymysql as mysp\n",
    "#mydb=mysp.connect(host='localhost',user='root',password='')\n",
    "#mycursor = mydb.cursor()\n",
    "#mycursor.execute('use db1;')\n",
    "\n",
    "class preprocesses:\n",
    "    def __init__(self, input_datadir, output_datadir):\n",
    "        self.input_datadir = input_datadir\n",
    "        self.output_datadir = output_datadir\n",
    "\n",
    "    def collect_data(self):\n",
    "        output_dir = os.path.expanduser(self.output_datadir)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        dataset = facenet.get_dataset(self.input_datadir)\n",
    "        with tf.Graph().as_default():\n",
    "            gpu_options =tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "            sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "            with sess.as_default():\n",
    "                pnet, rnet, onet = create_mtcnn(sess, 'C:/Users/user/npy')\n",
    "\n",
    "        minsize = 20  # minimum size of face\n",
    "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "        factor = 0.709  # scale factor\n",
    "        margin = 44\n",
    "        image_size = 182\n",
    "\n",
    "        # Add a random key to the filename to allow alignment using multiple processes\n",
    "        random_key = np.random.randint(0, high=99999)\n",
    "        bounding_boxes_filename = os.path.join(output_dir, 'bounding_boxes_%05d.txt' % random_key)\n",
    "\n",
    "        with open(bounding_boxes_filename, \"w\") as text_file:\n",
    "            nrof_images_total = 0\n",
    "            nrof_successfully_aligned = 0\n",
    "            for cls in dataset:\n",
    "                output_class_dir = os.path.join(output_dir, cls.name)\n",
    "                if not os.path.exists(output_class_dir):\n",
    "                    os.makedirs(output_class_dir)\n",
    "                for image_path in cls.image_paths:\n",
    "                    nrof_images_total += 1\n",
    "                    filename = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "                    output_filename = os.path.join(output_class_dir, filename + '.png')\n",
    "                    print(\"Image: %s\" % image_path)\n",
    "                    if not os.path.exists(output_filename):\n",
    "                        try:\n",
    "                            img = imageio.imread(image_path)\n",
    "                        except (IOError, ValueError, IndexError) as e:\n",
    "                            errorMessage = '{}: {}'.format(image_path, e)\n",
    "                            print(errorMessage)\n",
    "                        else:\n",
    "                            if img.ndim < 2:\n",
    "                                print('Unable to align \"%s\"' % image_path)\n",
    "                                text_file.write('%s\\n' % (output_filename))\n",
    "                                continue\n",
    "                            if img.ndim == 2:\n",
    "                                img = facenet.to_rgb(img)\n",
    "                                print('to_rgb data dimension: ', img.ndim)\n",
    "                            img = img[:, :, 0:3]\n",
    "\n",
    "                            bounding_boxes, _ = detect_face(img, minsize, pnet, rnet, onet, threshold,\n",
    "                                                                        factor)\n",
    "                            nrof_faces = bounding_boxes.shape[0]\n",
    "                            print('No of Detected Face: %d' % nrof_faces)\n",
    "                            if nrof_faces > 0:\n",
    "                                det = bounding_boxes[:, 0:4]\n",
    "                                img_size = np.asarray(img.shape)[0:2]\n",
    "                                if nrof_faces > 1:\n",
    "                                    bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])\n",
    "                                    img_center = img_size / 2\n",
    "                                    offsets = np.vstack([(det[:, 0] + det[:, 2]) / 2 - img_center[1],\n",
    "                                                         (det[:, 1] + det[:, 3]) / 2 - img_center[0]])\n",
    "                                    offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n",
    "                                    index = np.argmax(\n",
    "                                        bounding_box_size - offset_dist_squared * 2.0)  # some extra weight on the centering\n",
    "                                    det = det[index, :]\n",
    "                                det = np.squeeze(det)\n",
    "                                bb_temp = np.zeros(4, dtype=np.int32)\n",
    "\n",
    "                                bb_temp[0] = det[0]\n",
    "                                bb_temp[1] = det[1]\n",
    "                                bb_temp[2] = det[2]\n",
    "                                bb_temp[3] = det[3]\n",
    "\n",
    "                                cropped_temp = img[bb_temp[1]:bb_temp[3], bb_temp[0]:bb_temp[2], :]\n",
    "                                #scaled_temp = misc.imresize(cropped_temp, (image_size, image_size), interp='bilinear')\n",
    "                                scaled_temp = numpy.array(Image.fromarray(cropped_temp).resize(size=(image_size, image_size)))\n",
    "                                                                \n",
    "\n",
    "                                nrof_successfully_aligned += 1\n",
    "                                imageio.imwrite(output_filename, scaled_temp)\n",
    "                                text_file.write('%s %d %d %d %d\\n' % (\n",
    "                                output_filename, bb_temp[0], bb_temp[1], bb_temp[2], bb_temp[3]))\n",
    "                            else:\n",
    "                                print('Unable to align \"%s\"' % image_path)\n",
    "                                text_file.write('%s\\n' % (output_filename))\n",
    "\n",
    "        return (nrof_images_total,nrof_successfully_aligned)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def layer(op):\n",
    "    '''Decorator for composable network layers.'''\n",
    "\n",
    "    def layer_decorated(self, *args, **kwargs):\n",
    "        # Automatically set a name if not provided.\n",
    "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n",
    "        # Figure out the layer inputs.\n",
    "        if len(self.terminals) == 0:\n",
    "            raise RuntimeError('No input variables found for layer %s.' % name)\n",
    "        elif len(self.terminals) == 1:\n",
    "            layer_input = self.terminals[0]\n",
    "        else:\n",
    "            layer_input = list(self.terminals)\n",
    "        # Perform the operation and get the output.\n",
    "        layer_output = op(self, layer_input, *args, **kwargs)\n",
    "        # Add to layer LUT.\n",
    "        self.layers[name] = layer_output\n",
    "        # This output is now the input for the next layer.\n",
    "        self.feed(layer_output)\n",
    "        # Return self for chained calls.\n",
    "        return self\n",
    "\n",
    "    return layer_decorated\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, inputs, trainable=True):\n",
    "        # The input nodes for this network\n",
    "        self.inputs = inputs\n",
    "        # The current list of terminal nodes\n",
    "        self.terminals = []\n",
    "        # Mapping from layer names to layers\n",
    "        self.layers = dict(inputs)\n",
    "        # If true, the resulting variables are set as trainable\n",
    "        self.trainable = trainable\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        '''Construct the network. '''\n",
    "        raise NotImplementedError('Must be implemented by the subclass.')\n",
    "\n",
    "    def load(self, data_path, session, ignore_missing=False):\n",
    "        '''Load network weights.\n",
    "        data_path: The path to the numpy-serialized network weights\n",
    "        session: The current TensorFlow session\n",
    "        ignore_missing: If true, serialized weights for missing layers are ignored.\n",
    "        '''\n",
    "        data_dict = np.load(data_path, encoding='latin1',allow_pickle=True).item() #pylint: disable=no-member\n",
    "\n",
    "        for op_name in data_dict:\n",
    "            with tf.compat.v1.variable_scope(op_name, reuse=True):\n",
    "                for param_name, data in iteritems(data_dict[op_name]):\n",
    "                    try:\n",
    "                        var = tf.compat.v1.get_variable(param_name)\n",
    "                        session.run(var.assign(data))\n",
    "                    except ValueError:\n",
    "                        if not ignore_missing:\n",
    "                            raise\n",
    "\n",
    "    def feed(self, *args):\n",
    "        '''Set the input(s) for the next operation by replacing the terminal nodes.\n",
    "        The arguments can be either layer names or the actual layers.\n",
    "        '''\n",
    "        assert len(args) != 0\n",
    "        self.terminals = []\n",
    "        for fed_layer in args:\n",
    "            if isinstance(fed_layer, string_types):\n",
    "                try:\n",
    "                    fed_layer = self.layers[fed_layer]\n",
    "                except KeyError:\n",
    "                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n",
    "            self.terminals.append(fed_layer)\n",
    "        return self\n",
    "\n",
    "    def get_output(self):\n",
    "        '''Returns the current network output.'''\n",
    "        return self.terminals[-1]\n",
    "\n",
    "    def get_unique_name(self, prefix):\n",
    "        '''Returns an index-suffixed unique name for the given prefix.\n",
    "        This is used for auto-generating layer names based on the type-prefix.\n",
    "        '''\n",
    "        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n",
    "        return '%s_%d' % (prefix, ident)\n",
    "\n",
    "    def make_var(self, name, shape):\n",
    "        '''Creates a new TensorFlow variable.'''\n",
    "        return tf.compat.v1.get_variable(name, shape, trainable=self.trainable)\n",
    "\n",
    "    def validate_padding(self, padding):\n",
    "        '''Verifies that the padding is one of the supported ones.'''\n",
    "        assert padding in ('SAME', 'VALID')\n",
    "\n",
    "    @layer\n",
    "    def conv(self,\n",
    "             inp,\n",
    "             k_h,\n",
    "             k_w,\n",
    "             c_o,\n",
    "             s_h,\n",
    "             s_w,\n",
    "             name,\n",
    "             relu=True,\n",
    "             padding='SAME',\n",
    "             group=1,\n",
    "             biased=True):\n",
    "        # Verify that the padding is acceptable\n",
    "        self.validate_padding(padding)\n",
    "        # Get the number of channels in the input\n",
    "        c_i = int(inp.get_shape()[-1])\n",
    "        # Verify that the grouping parameter is valid\n",
    "        assert c_i % group == 0\n",
    "        assert c_o % group == 0\n",
    "        # Convolution for a given input and kernel\n",
    "        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "        with tf.compat.v1.variable_scope(name) as scope:\n",
    "            kernel = self.make_var('weights', shape=[k_h, k_w, c_i // group, c_o])\n",
    "            # This is the common-case. Convolve the input without any further complications.\n",
    "            output = convolve(inp, kernel)\n",
    "            # Add the biases\n",
    "            if biased:\n",
    "                biases = self.make_var('biases', [c_o])\n",
    "                output = tf.nn.bias_add(output, biases)\n",
    "            if relu:\n",
    "                # ReLU non-linearity\n",
    "                output = tf.nn.relu(output, name=scope.name)\n",
    "            return output\n",
    "\n",
    "    @layer\n",
    "    def prelu(self, inp, name):\n",
    "        with tf.compat.v1.variable_scope(name):\n",
    "            i = int(inp.get_shape()[-1])\n",
    "            alpha = self.make_var('alpha', shape=(i,))\n",
    "            output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n",
    "        return output\n",
    "\n",
    "    @layer\n",
    "    def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding='SAME'):\n",
    "        self.validate_padding(padding)\n",
    "        return tf.nn.max_pool(inp,\n",
    "                              ksize=[1, k_h, k_w, 1],\n",
    "                              strides=[1, s_h, s_w, 1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    @layer\n",
    "    def fc(self, inp, num_out, name, relu=True):\n",
    "        with tf.compat.v1.variable_scope(name):\n",
    "            input_shape = inp.get_shape()\n",
    "            if input_shape.ndims == 4:\n",
    "                # The input is spatial. Vectorize it first.\n",
    "                dim = 1\n",
    "                for d in input_shape[1:].as_list():\n",
    "                    dim *= int(d)\n",
    "                feed_in = tf.reshape(inp, [-1, dim])\n",
    "            else:\n",
    "                feed_in, dim = (inp, input_shape[-1])\n",
    "            weights = self.make_var('weights', shape=[dim, num_out])\n",
    "            biases = self.make_var('biases', [num_out])\n",
    "            op = tf.nn.relu_layer if relu else tf.compat.v1.nn.xw_plus_b\n",
    "            fc = op(feed_in, weights, biases, name=name)\n",
    "            return fc\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Multi dimensional softmax,\n",
    "    refer to https://github.com/tensorflow/tensorflow/issues/210\n",
    "    compute softmax along the dimension of target\n",
    "    the native softmax only supports batch_size x dimension\n",
    "    \"\"\"\n",
    "    @layer\n",
    "    def softmax(self, target, axis, name=None):\n",
    "        max_axis = tf.reduce_max(target, axis, keepdims=True)\n",
    "        target_exp = tf.exp(target-max_axis)\n",
    "        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n",
    "        softmax = tf.math.divide(target_exp, normalize, name)\n",
    "        return softmax\n",
    "    \n",
    "class PNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='PReLU1')\n",
    "             .max_pool(2, 2, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 16, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='PReLU2')\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='PReLU3')\n",
    "             .conv(1, 1, 2, 1, 1, relu=False, name='conv4-1')\n",
    "             .softmax(3,name='prob1'))\n",
    "\n",
    "        (self.feed('PReLU3') #pylint: disable=no-value-for-parameter\n",
    "             .conv(1, 1, 4, 1, 1, relu=False, name='conv4-2'))\n",
    "        \n",
    "class RNet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 28, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 48, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(2, 2, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .fc(128, relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(2, relu=False, name='conv5-1')\n",
    "             .softmax(1,name='prob1'))\n",
    "\n",
    "        (self.feed('prelu4') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv5-2'))\n",
    "\n",
    "class ONet(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data') #pylint: disable=no-value-for-parameter, no-member\n",
    "             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv1')\n",
    "             .prelu(name='prelu1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv2')\n",
    "             .prelu(name='prelu2')\n",
    "             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(3, 3, 64, 1, 1, padding='VALID', relu=False, name='conv3')\n",
    "             .prelu(name='prelu3')\n",
    "             .max_pool(2, 2, 2, 2, name='pool3')\n",
    "             .conv(2, 2, 128, 1, 1, padding='VALID', relu=False, name='conv4')\n",
    "             .prelu(name='prelu4')\n",
    "             .fc(256, relu=False, name='conv5')\n",
    "             .prelu(name='prelu5')\n",
    "             .fc(2, relu=False, name='conv6-1')\n",
    "             .softmax(1, name='prob1'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(4, relu=False, name='conv6-2'))\n",
    "\n",
    "        (self.feed('prelu5') #pylint: disable=no-value-for-parameter\n",
    "             .fc(10, relu=False, name='conv6-3'))\n",
    "\n",
    "def create_mtcnn(sess, model_path):\n",
    "    if not model_path:\n",
    "        model_path,_ = os.path.split(os.path.realpath(__file__))\n",
    "\n",
    "    with tf.compat.v1.variable_scope('pnet'):\n",
    "        data = tf.compat.v1.placeholder(tf.float32, (None,None,None,3), 'input')\n",
    "        pnet = PNet({'data':data})\n",
    "        pnet.load(os.path.join(model_path, 'det1.npy'), sess)\n",
    "    with tf.compat.v1.variable_scope('rnet'):\n",
    "        data = tf.compat.v1.placeholder(tf.float32, (None,24,24,3), 'input')\n",
    "        rnet = RNet({'data':data})\n",
    "        rnet.load(os.path.join(model_path, 'det2.npy'), sess)\n",
    "    with tf.compat.v1.variable_scope('onet'):\n",
    "        data = tf.compat.v1.placeholder(tf.float32, (None,48,48,3), 'input')\n",
    "        onet = ONet({'data':data})\n",
    "        onet.load(os.path.join(model_path, 'det3.npy'), sess)\n",
    "        \n",
    "    pnet_fun = lambda img : sess.run(('pnet/conv4-2/BiasAdd:0', 'pnet/prob1:0'), feed_dict={'pnet/input:0':img})\n",
    "    rnet_fun = lambda img : sess.run(('rnet/conv5-2/conv5-2:0', 'rnet/prob1:0'), feed_dict={'rnet/input:0':img})\n",
    "    onet_fun = lambda img : sess.run(('onet/conv6-2/conv6-2:0', 'onet/conv6-3/conv6-3:0', 'onet/prob1:0'), feed_dict={'onet/input:0':img})\n",
    "    return pnet_fun, rnet_fun, onet_fun\n",
    "\n",
    "def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n",
    "    # im: input image\n",
    "    # minsize: minimum of faces' size\n",
    "    # pnet, rnet, onet: caffemodel\n",
    "    # threshold: threshold=[th1 th2 th3], th1-3 are three steps's threshold\n",
    "    # fastresize: resize img from last scale (using in high-resolution images) if fastresize==true\n",
    "    factor_count=0\n",
    "    total_boxes=np.empty((0,9))\n",
    "    points=np.empty(0)\n",
    "    h=img.shape[0]\n",
    "    w=img.shape[1]\n",
    "    minl=np.amin([h, w])\n",
    "    m=12.0/minsize\n",
    "    minl=minl*m\n",
    "    # creat scale pyramid\n",
    "    scales=[]\n",
    "    while minl>=12:\n",
    "        scales += [m*np.power(factor, factor_count)]\n",
    "        minl = minl*factor\n",
    "        factor_count += 1\n",
    "\n",
    "    # first stage\n",
    "    for j in range(len(scales)):\n",
    "        scale=scales[j]\n",
    "        hs=int(np.ceil(h*scale))\n",
    "        ws=int(np.ceil(w*scale))\n",
    "        im_data = imresample(img, (hs, ws))\n",
    "        im_data = (im_data-127.5)*0.0078125\n",
    "        img_x = np.expand_dims(im_data, 0)\n",
    "        img_y = np.transpose(img_x, (0,2,1,3))\n",
    "        out = pnet(img_y)\n",
    "        out0 = np.transpose(out[0], (0,2,1,3))\n",
    "        out1 = np.transpose(out[1], (0,2,1,3))\n",
    "        \n",
    "        boxes, _ = generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scale, threshold[0])\n",
    "        \n",
    "        # inter-scale nms\n",
    "        pick = nms(boxes.copy(), 0.5, 'Union')\n",
    "        if boxes.size>0 and pick.size>0:\n",
    "            boxes = boxes[pick,:]\n",
    "            total_boxes = np.append(total_boxes, boxes, axis=0)\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        pick = nms(total_boxes.copy(), 0.7, 'Union')\n",
    "        total_boxes = total_boxes[pick,:]\n",
    "        regw = total_boxes[:,2]-total_boxes[:,0]\n",
    "        regh = total_boxes[:,3]-total_boxes[:,1]\n",
    "        qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n",
    "        qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n",
    "        qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n",
    "        qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n",
    "        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n",
    "        total_boxes = rerec(total_boxes.copy())\n",
    "        total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n",
    "        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        # second stage\n",
    "        tempimg = np.zeros((24,24,3,numbox))\n",
    "        for k in range(0,numbox):\n",
    "            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                tempimg[:,:,:,k] = imresample(tmp, (24, 24))\n",
    "            else:\n",
    "                return np.empty()\n",
    "        tempimg = (tempimg-127.5)*0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "        out = rnet(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        score = out1[1,:]\n",
    "        ipass = np.where(score>threshold[1])\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "        mv = out0[:,ipass[0]]\n",
    "        if total_boxes.shape[0]>0:\n",
    "            pick = nms(total_boxes, 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n",
    "            total_boxes = rerec(total_boxes.copy())\n",
    "\n",
    "    numbox = total_boxes.shape[0]\n",
    "    if numbox>0:\n",
    "        # third stage\n",
    "        total_boxes = np.fix(total_boxes).astype(np.int32)\n",
    "        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n",
    "        tempimg = np.zeros((48,48,3,numbox))\n",
    "        for k in range(0,numbox):\n",
    "            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n",
    "            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n",
    "            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n",
    "                tempimg[:,:,:,k] = imresample(tmp, (48, 48))\n",
    "            else:\n",
    "                return np.empty()\n",
    "        tempimg = (tempimg-127.5)*0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n",
    "        out = onet(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        out2 = np.transpose(out[2])\n",
    "        score = out2[1,:]\n",
    "        points = out1\n",
    "        ipass = np.where(score>threshold[2])\n",
    "        points = points[:,ipass[0]]\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n",
    "        mv = out0[:,ipass[0]]\n",
    "\n",
    "        w = total_boxes[:,2]-total_boxes[:,0]+1\n",
    "        h = total_boxes[:,3]-total_boxes[:,1]+1\n",
    "        points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n",
    "        points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n",
    "        if total_boxes.shape[0]>0:\n",
    "            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))\n",
    "            pick = nms(total_boxes.copy(), 0.7, 'Min')\n",
    "            total_boxes = total_boxes[pick,:]\n",
    "            points = points[:,pick]\n",
    "                \n",
    "    return total_boxes, points\n",
    "\n",
    "\n",
    "def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, threshold, factor):\n",
    "    # im: input image\n",
    "    # minsize: minimum of faces' size\n",
    "    # pnet, rnet, onet: caffemodel\n",
    "    # threshold: threshold=[th1 th2 th3], th1-3 are three steps's threshold [0-1]\n",
    "\n",
    "    all_scales = [None] * len(images)\n",
    "    images_with_boxes = [None] * len(images)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        images_with_boxes[i] = {'total_boxes': np.empty((0, 9))}\n",
    "\n",
    "    # create scale pyramid\n",
    "    for index, img in enumerate(images):\n",
    "        all_scales[index] = []\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "        minsize = int(detection_window_size_ratio * np.minimum(w, h))\n",
    "        factor_count = 0\n",
    "        minl = np.amin([h, w])\n",
    "        if minsize <= 12:\n",
    "            minsize = 12\n",
    "\n",
    "        m = 12.0 / minsize\n",
    "        minl = minl * m\n",
    "        while minl >= 12:\n",
    "            all_scales[index].append(m * np.power(factor, factor_count))\n",
    "            minl = minl * factor\n",
    "            factor_count += 1\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # first stage - fast proposal network (pnet) to obtain face candidates\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    images_obj_per_resolution = {}\n",
    "\n",
    "    # TODO: use some type of rounding to number module 8 to increase probability that pyramid images will have the same resolution across input images\n",
    "\n",
    "    for index, scales in enumerate(all_scales):\n",
    "        h = images[index].shape[0]\n",
    "        w = images[index].shape[1]\n",
    "\n",
    "        for scale in scales:\n",
    "            hs = int(np.ceil(h * scale))\n",
    "            ws = int(np.ceil(w * scale))\n",
    "\n",
    "            if (ws, hs) not in images_obj_per_resolution:\n",
    "                images_obj_per_resolution[(ws, hs)] = []\n",
    "\n",
    "            im_data = imresample(images[index], (hs, ws))\n",
    "            im_data = (im_data - 127.5) * 0.0078125\n",
    "            img_y = np.transpose(im_data, (1, 0, 2))  # caffe uses different dimensions ordering\n",
    "            images_obj_per_resolution[(ws, hs)].append({'scale': scale, 'image': img_y, 'index': index})\n",
    "\n",
    "    for resolution in images_obj_per_resolution:\n",
    "        images_per_resolution = [i['image'] for i in images_obj_per_resolution[resolution]]\n",
    "        outs = pnet(images_per_resolution)\n",
    "\n",
    "        for index in range(len(outs[0])):\n",
    "            scale = images_obj_per_resolution[resolution][index]['scale']\n",
    "            image_index = images_obj_per_resolution[resolution][index]['index']\n",
    "            out0 = np.transpose(outs[0][index], (1, 0, 2))\n",
    "            out1 = np.transpose(outs[1][index], (1, 0, 2))\n",
    "\n",
    "            boxes, _ = generateBoundingBox(out1[:, :, 1].copy(), out0[:, :, :].copy(), scale, threshold[0])\n",
    "\n",
    "            # inter-scale nms\n",
    "            pick = nms(boxes.copy(), 0.5, 'Union')\n",
    "            if boxes.size > 0 and pick.size > 0:\n",
    "                boxes = boxes[pick, :]\n",
    "                images_with_boxes[image_index]['total_boxes'] = np.append(images_with_boxes[image_index]['total_boxes'],\n",
    "                                                                          boxes,\n",
    "                                                                          axis=0)\n",
    "\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        numbox = image_obj['total_boxes'].shape[0]\n",
    "        if numbox > 0:\n",
    "            h = images[index].shape[0]\n",
    "            w = images[index].shape[1]\n",
    "            pick = nms(image_obj['total_boxes'].copy(), 0.7, 'Union')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            regw = image_obj['total_boxes'][:, 2] - image_obj['total_boxes'][:, 0]\n",
    "            regh = image_obj['total_boxes'][:, 3] - image_obj['total_boxes'][:, 1]\n",
    "            qq1 = image_obj['total_boxes'][:, 0] + image_obj['total_boxes'][:, 5] * regw\n",
    "            qq2 = image_obj['total_boxes'][:, 1] + image_obj['total_boxes'][:, 6] * regh\n",
    "            qq3 = image_obj['total_boxes'][:, 2] + image_obj['total_boxes'][:, 7] * regw\n",
    "            qq4 = image_obj['total_boxes'][:, 3] + image_obj['total_boxes'][:, 8] * regh\n",
    "            image_obj['total_boxes'] = np.transpose(np.vstack([qq1, qq2, qq3, qq4, image_obj['total_boxes'][:, 4]]))\n",
    "            image_obj['total_boxes'] = rerec(image_obj['total_boxes'].copy())\n",
    "            image_obj['total_boxes'][:, 0:4] = np.fix(image_obj['total_boxes'][:, 0:4]).astype(np.int32)\n",
    "            dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj['total_boxes'].copy(), w, h)\n",
    "\n",
    "            numbox = image_obj['total_boxes'].shape[0]\n",
    "            tempimg = np.zeros((24, 24, 3, numbox))\n",
    "\n",
    "            if numbox > 0:\n",
    "                for k in range(0, numbox):\n",
    "                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n",
    "                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n",
    "                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                        tempimg[:, :, :, k] = imresample(tmp, (24, 24))\n",
    "                    else:\n",
    "                        return np.empty()\n",
    "\n",
    "                tempimg = (tempimg - 127.5) * 0.0078125\n",
    "                image_obj['rnet_input'] = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # second stage - refinement of face candidates with rnet\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    bulk_rnet_input = np.empty((0, 24, 24, 3))\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'rnet_input' in image_obj:\n",
    "            bulk_rnet_input = np.append(bulk_rnet_input, image_obj['rnet_input'], axis=0)\n",
    "\n",
    "    out = rnet(bulk_rnet_input)\n",
    "    out0 = np.transpose(out[0])\n",
    "    out1 = np.transpose(out[1])\n",
    "    score = out1[1, :]\n",
    "\n",
    "    i = 0\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'rnet_input' not in image_obj:\n",
    "            continue\n",
    "\n",
    "        rnet_input_count = image_obj['rnet_input'].shape[0]\n",
    "        score_per_image = score[i:i + rnet_input_count]\n",
    "        out0_per_image = out0[:, i:i + rnet_input_count]\n",
    "\n",
    "        ipass = np.where(score_per_image > threshold[1])\n",
    "        image_obj['total_boxes'] = np.hstack([image_obj['total_boxes'][ipass[0], 0:4].copy(),\n",
    "                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n",
    "\n",
    "        mv = out0_per_image[:, ipass[0]]\n",
    "\n",
    "        if image_obj['total_boxes'].shape[0] > 0:\n",
    "            h = images[index].shape[0]\n",
    "            w = images[index].shape[1]\n",
    "            pick = nms(image_obj['total_boxes'], 0.7, 'Union')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            image_obj['total_boxes'] = bbreg(image_obj['total_boxes'].copy(), np.transpose(mv[:, pick]))\n",
    "            image_obj['total_boxes'] = rerec(image_obj['total_boxes'].copy())\n",
    "\n",
    "            numbox = image_obj['total_boxes'].shape[0]\n",
    "\n",
    "            if numbox > 0:\n",
    "                tempimg = np.zeros((48, 48, 3, numbox))\n",
    "                image_obj['total_boxes'] = np.fix(image_obj['total_boxes']).astype(np.int32)\n",
    "                dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj['total_boxes'].copy(), w, h)\n",
    "\n",
    "                for k in range(0, numbox):\n",
    "                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n",
    "                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n",
    "                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                        tempimg[:, :, :, k] = imresample(tmp, (48, 48))\n",
    "                    else:\n",
    "                        return np.empty()\n",
    "                tempimg = (tempimg - 127.5) * 0.0078125\n",
    "                image_obj['onet_input'] = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "        i += rnet_input_count\n",
    "\n",
    "    # # # # # # # # # # # # #\n",
    "    # third stage - further refinement and facial landmarks positions with onet\n",
    "    # # # # # # # # # # # # #\n",
    "\n",
    "    bulk_onet_input = np.empty((0, 48, 48, 3))\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'onet_input' in image_obj:\n",
    "            bulk_onet_input = np.append(bulk_onet_input, image_obj['onet_input'], axis=0)\n",
    "\n",
    "    out = onet(bulk_onet_input)\n",
    "\n",
    "    out0 = np.transpose(out[0])\n",
    "    out1 = np.transpose(out[1])\n",
    "    out2 = np.transpose(out[2])\n",
    "    score = out2[1, :]\n",
    "    points = out1\n",
    "\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for index, image_obj in enumerate(images_with_boxes):\n",
    "        if 'onet_input' not in image_obj:\n",
    "            ret.append(None)\n",
    "            continue\n",
    "\n",
    "        onet_input_count = image_obj['onet_input'].shape[0]\n",
    "\n",
    "        out0_per_image = out0[:, i:i + onet_input_count]\n",
    "        score_per_image = score[i:i + onet_input_count]\n",
    "        points_per_image = points[:, i:i + onet_input_count]\n",
    "\n",
    "        ipass = np.where(score_per_image > threshold[2])\n",
    "        points_per_image = points_per_image[:, ipass[0]]\n",
    "\n",
    "        image_obj['total_boxes'] = np.hstack([image_obj['total_boxes'][ipass[0], 0:4].copy(),\n",
    "                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n",
    "        mv = out0_per_image[:, ipass[0]]\n",
    "\n",
    "        w = image_obj['total_boxes'][:, 2] - image_obj['total_boxes'][:, 0] + 1\n",
    "        h = image_obj['total_boxes'][:, 3] - image_obj['total_boxes'][:, 1] + 1\n",
    "        points_per_image[0:5, :] = np.tile(w, (5, 1)) * points_per_image[0:5, :] + np.tile(\n",
    "            image_obj['total_boxes'][:, 0], (5, 1)) - 1\n",
    "        points_per_image[5:10, :] = np.tile(h, (5, 1)) * points_per_image[5:10, :] + np.tile(\n",
    "            image_obj['total_boxes'][:, 1], (5, 1)) - 1\n",
    "\n",
    "        if image_obj['total_boxes'].shape[0] > 0:\n",
    "            image_obj['total_boxes'] = bbreg(image_obj['total_boxes'].copy(), np.transpose(mv))\n",
    "            pick = nms(image_obj['total_boxes'].copy(), 0.7, 'Min')\n",
    "            image_obj['total_boxes'] = image_obj['total_boxes'][pick, :]\n",
    "            points_per_image = points_per_image[:, pick]\n",
    "\n",
    "            ret.append((image_obj['total_boxes'], points_per_image))\n",
    "        else:\n",
    "            ret.append(None)\n",
    "\n",
    "        i += onet_input_count\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "# function [boundingbox] = bbreg(boundingbox,reg)\n",
    "def bbreg(boundingbox,reg):\n",
    "    # calibrate bounding boxes\n",
    "    if reg.shape[1]==1:\n",
    "        reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n",
    "\n",
    "    w = boundingbox[:,2]-boundingbox[:,0]+1\n",
    "    h = boundingbox[:,3]-boundingbox[:,1]+1\n",
    "    b1 = boundingbox[:,0]+reg[:,0]*w\n",
    "    b2 = boundingbox[:,1]+reg[:,1]*h\n",
    "    b3 = boundingbox[:,2]+reg[:,2]*w\n",
    "    b4 = boundingbox[:,3]+reg[:,3]*h\n",
    "    boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n",
    "    return boundingbox\n",
    " \n",
    "def generateBoundingBox(imap, reg, scale, t):\n",
    "    # use heatmap to generate bounding boxes\n",
    "    stride=2\n",
    "    cellsize=12\n",
    "\n",
    "    imap = np.transpose(imap)\n",
    "    dx1 = np.transpose(reg[:,:,0])\n",
    "    dy1 = np.transpose(reg[:,:,1])\n",
    "    dx2 = np.transpose(reg[:,:,2])\n",
    "    dy2 = np.transpose(reg[:,:,3])\n",
    "    y, x = np.where(imap >= t)\n",
    "    if y.shape[0]==1:\n",
    "        dx1 = np.flipud(dx1)\n",
    "        dy1 = np.flipud(dy1)\n",
    "        dx2 = np.flipud(dx2)\n",
    "        dy2 = np.flipud(dy2)\n",
    "    score = imap[(y,x)]\n",
    "    reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n",
    "    if reg.size==0:\n",
    "        reg = np.empty((0,3))\n",
    "    bb = np.transpose(np.vstack([y,x]))\n",
    "    q1 = np.fix((stride*bb+1)/scale)\n",
    "    q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n",
    "    boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n",
    "    return boundingbox, reg\n",
    " \n",
    "# function pick = nms(boxes,threshold,type)\n",
    "def nms(boxes, threshold, method):\n",
    "    if boxes.size==0:\n",
    "        return np.empty((0,3))\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    s = boxes[:,4]\n",
    "    area = (x2-x1+1) * (y2-y1+1)\n",
    "    I = np.argsort(s)\n",
    "    pick = np.zeros_like(s, dtype=np.int16)\n",
    "    counter = 0\n",
    "    while I.size>0:\n",
    "        i = I[-1]\n",
    "        pick[counter] = i\n",
    "        counter += 1\n",
    "        idx = I[0:-1]\n",
    "        xx1 = np.maximum(x1[i], x1[idx])\n",
    "        yy1 = np.maximum(y1[i], y1[idx])\n",
    "        xx2 = np.minimum(x2[i], x2[idx])\n",
    "        yy2 = np.minimum(y2[i], y2[idx])\n",
    "        w = np.maximum(0.0, xx2-xx1+1)\n",
    "        h = np.maximum(0.0, yy2-yy1+1)\n",
    "        inter = w * h\n",
    "        if method is 'Min':\n",
    "            o = inter / np.minimum(area[i], area[idx])\n",
    "        else:\n",
    "            o = inter / (area[i] + area[idx] - inter)\n",
    "        I = I[np.where(o<=threshold)]\n",
    "    pick = pick[0:counter]\n",
    "    return pick\n",
    "\n",
    "# function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n",
    "def pad(total_boxes, w, h):\n",
    "    # compute the padding coordinates (pad the bounding boxes to square)\n",
    "    tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n",
    "    tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n",
    "    numbox = total_boxes.shape[0]\n",
    "\n",
    "    dx = np.ones((numbox), dtype=np.int32)\n",
    "    dy = np.ones((numbox), dtype=np.int32)\n",
    "    edx = tmpw.copy().astype(np.int32)\n",
    "    edy = tmph.copy().astype(np.int32)\n",
    "\n",
    "    x = total_boxes[:,0].copy().astype(np.int32)\n",
    "    y = total_boxes[:,1].copy().astype(np.int32)\n",
    "    ex = total_boxes[:,2].copy().astype(np.int32)\n",
    "    ey = total_boxes[:,3].copy().astype(np.int32)\n",
    "\n",
    "    tmp = np.where(ex>w)\n",
    "    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n",
    "    ex[tmp] = w\n",
    "    \n",
    "    tmp = np.where(ey>h)\n",
    "    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n",
    "    ey[tmp] = h\n",
    "\n",
    "    tmp = np.where(x<1)\n",
    "    dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n",
    "    x[tmp] = 1\n",
    "\n",
    "    tmp = np.where(y<1)\n",
    "    dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n",
    "    y[tmp] = 1\n",
    "    \n",
    "    return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n",
    "\n",
    "# function [bboxA] = rerec(bboxA)\n",
    "def rerec(bboxA):\n",
    "    # convert bboxA to square\n",
    "    h = bboxA[:,3]-bboxA[:,1]\n",
    "    w = bboxA[:,2]-bboxA[:,0]\n",
    "    l = np.maximum(w, h)\n",
    "    bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n",
    "    bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n",
    "    bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n",
    "    return bboxA\n",
    "\n",
    "def imresample(img, sz):\n",
    "    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA) #@UndefinedVariable\n",
    "    return im_data\n",
    "\n",
    "    # This method is kept for debugging purpose\n",
    "#     h=img.shape[0]\n",
    "#     w=img.shape[1]\n",
    "#     hs, ws = sz\n",
    "#     dx = float(w) / ws\n",
    "#     dy = float(h) / hs\n",
    "#     im_data = np.zeros((hs,ws,3))\n",
    "#     for a1 in range(0,hs):\n",
    "#         for a2 in range(0,ws):\n",
    "#             for a3 in range(0,3):\n",
    "#                 im_data[a1,a2,a3] = img[int(floor(a1*dy)),int(floor(a2*dx)),a3]\n",
    "#     return im_data\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import facenet\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "\n",
    "class training:\n",
    "    def __init__(self, datadir, modeldir,classifier_filename):\n",
    "        self.datadir = datadir\n",
    "        self.modeldir = modeldir\n",
    "        self.classifier_filename = classifier_filename\n",
    "\n",
    "    def main_train(self):\n",
    "        with tf.Graph().as_default():\n",
    "            with tf.compat.v1.Session() as sess:\n",
    "                img_data = facenet.get_dataset(self.datadir)\n",
    "                path, label = facenet.get_image_paths_and_labels(img_data)\n",
    "                print('Classes: %d' % len(img_data))\n",
    "                print('Images: %d' % len(path))\n",
    "\n",
    "                load_model(self.modeldir)\n",
    "                images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "                embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "                phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "                embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "                print('Extracting features of images for model')\n",
    "                batch_size = 1000\n",
    "                image_size = 160\n",
    "                nrof_images = len(path)\n",
    "                nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\n",
    "                emb_array = np.zeros((nrof_images, embedding_size))\n",
    "                for i in range(nrof_batches_per_epoch):\n",
    "                    start_index = i * batch_size\n",
    "                    end_index = min((i + 1) * batch_size, nrof_images)\n",
    "                    paths_batch = path[start_index:end_index]\n",
    "                    images = load_data(paths_batch, False, False, image_size)\n",
    "                    feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n",
    "                    emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "                classifier_file_name = os.path.expanduser(self.classifier_filename)\n",
    "\n",
    "                # Training Started\n",
    "                print('Training Started')\n",
    "                model = SVC(kernel='linear', probability=True)\n",
    "                model.fit(emb_array, label)\n",
    "\n",
    "                class_names = [cls.name.replace('_', ' ') for cls in img_data]\n",
    "\n",
    "                # Saving model\n",
    "                with open(classifier_file_name, 'wb') as outfile:\n",
    "                    pickle.dump((model, class_names), outfile)\n",
    "                return classifier_file_name\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, alpha):\n",
    "    \"\"\"Calculate the triplet loss according to the FaceNet paper\n",
    "    \n",
    "    Args:\n",
    "      anchor: the embeddings for the anchor images.\n",
    "      positive: the embeddings for the positive images.\n",
    "      negative: the embeddings for the negative images.\n",
    "  \n",
    "    Returns:\n",
    "      the triplet loss according to the FaceNet paper as a float tensor.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('triplet_loss'):\n",
    "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
    "        \n",
    "        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
    "      \n",
    "    return loss\n",
    "  \n",
    "def decov_loss(xs):\n",
    "    \"\"\"Decov loss as described in https://arxiv.org/pdf/1511.06068.pdf\n",
    "    'Reducing Overfitting In Deep Networks by Decorrelating Representation'\n",
    "    \"\"\"\n",
    "    x = tf.reshape(xs, [int(xs.get_shape()[0]), -1])\n",
    "    m = tf.reduce_mean(x, 0, True)\n",
    "    z = tf.expand_dims(x-m, 2)\n",
    "    corr = tf.reduce_mean(tf.matmul(z, tf.transpose(z, perm=[0,2,1])), 0)\n",
    "    corr_frob_sqr = tf.reduce_sum(tf.square(corr))\n",
    "    corr_diag_sqr = tf.reduce_sum(tf.square(tf.diag_part(corr)))\n",
    "    loss = 0.5*(corr_frob_sqr - corr_diag_sqr)\n",
    "    return loss \n",
    "  \n",
    "def center_loss(features, label, alfa, nrof_classes):\n",
    "    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n",
    "       (http://ydwen.github.io/papers/WenECCV16.pdf)\n",
    "    \"\"\"\n",
    "    nrof_features = features.get_shape()[1]\n",
    "    centers = tf.get_variable('centers', [nrof_classes, nrof_features], dtype=tf.float32,\n",
    "        initializer=tf.constant_initializer(0), trainable=False)\n",
    "    label = tf.reshape(label, [-1])\n",
    "    centers_batch = tf.gather(centers, label)\n",
    "    diff = (1 - alfa) * (centers_batch - features)\n",
    "    centers = tf.scatter_sub(centers, label, diff)\n",
    "    loss = tf.reduce_mean(tf.square(features - centers_batch))\n",
    "    return loss, centers\n",
    "\n",
    "def get_image_paths_and_labels(dataset):\n",
    "    image_paths_flat = []\n",
    "    labels_flat = []\n",
    "    for i in range(len(dataset)):\n",
    "        image_paths_flat += dataset[i].image_paths\n",
    "        labels_flat += [i] * len(dataset[i].image_paths)\n",
    "    return image_paths_flat, labels_flat\n",
    "\n",
    "def shuffle_examples(image_paths, labels):\n",
    "    shuffle_list = list(zip(image_paths, labels))\n",
    "    random.shuffle(shuffle_list)\n",
    "    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n",
    "    return image_paths_shuff, labels_shuff\n",
    "\n",
    "def read_images_from_disk(input_queue):\n",
    "    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n",
    "    Args:\n",
    "      filename_and_label_tensor: A scalar string tensor.\n",
    "    Returns:\n",
    "      Two tensors: the decoded image, and the string label.\n",
    "    \"\"\"\n",
    "    label = input_queue[1]\n",
    "    file_contents = tf.read_file(input_queue[0])\n",
    "    example = tf.image.decode_png(file_contents, channels=3)\n",
    "    return example, label\n",
    "  \n",
    "def random_rotate_image(image):\n",
    "    angle = np.random.uniform(low=-10.0, high=10.0)\n",
    "    return misc.imrotate(image, angle, 'bicubic')\n",
    "  \n",
    "def read_and_augment_data(image_list, label_list, image_size, batch_size, max_nrof_epochs, \n",
    "        random_crop, random_flip, random_rotate, nrof_preprocess_threads, shuffle=True):\n",
    "    \n",
    "    images = ops.convert_to_tensor(image_list, dtype=tf.string)\n",
    "    labels = ops.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "    \n",
    "    # Makes an input queue\n",
    "    input_queue = tf.train.slice_input_producer([images, labels],\n",
    "        num_epochs=max_nrof_epochs, shuffle=shuffle)\n",
    "\n",
    "    images_and_labels = []\n",
    "    for _ in range(nrof_preprocess_threads):\n",
    "        image, label = read_images_from_disk(input_queue)\n",
    "        if random_rotate:\n",
    "            image = tf.py_func(random_rotate_image, [image], tf.uint8)\n",
    "        if random_crop:\n",
    "            image = tf.random_crop(image, [image_size, image_size, 3])\n",
    "        else:\n",
    "            image = tf.image.resize_image_with_crop_or_pad(image, image_size, image_size)\n",
    "        if random_flip:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "        #pylint: disable=no-member\n",
    "        image.set_shape((image_size, image_size, 3))\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "        images_and_labels.append([image, label])\n",
    "\n",
    "    image_batch, label_batch = tf.train.batch_join(\n",
    "        images_and_labels, batch_size=batch_size,\n",
    "        capacity=4 * nrof_preprocess_threads * batch_size,\n",
    "        allow_smaller_final_batch=True)\n",
    "  \n",
    "    return image_batch, label_batch\n",
    "  \n",
    "def _add_loss_summaries(total_loss):\n",
    "    \"\"\"Add summaries for losses.\n",
    "  \n",
    "    Generates moving average for all losses and associated summaries for\n",
    "    visualizing the performance of the network.\n",
    "  \n",
    "    Args:\n",
    "      total_loss: Total loss from loss().\n",
    "    Returns:\n",
    "      loss_averages_op: op for generating moving averages of losses.\n",
    "    \"\"\"\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    losses = tf.get_collection('losses')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "  \n",
    "    # Attach a scalar summmary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "        # as the original loss name.\n",
    "        tf.summary.scalar(l.op.name +' (raw)', l)\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "  \n",
    "    return loss_averages_op\n",
    "\n",
    "def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n",
    "    # Generate moving averages of all losses and associated summaries.\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        if optimizer=='ADAGRAD':\n",
    "            opt = tf.train.AdagradOptimizer(learning_rate)\n",
    "        elif optimizer=='ADADELTA':\n",
    "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n",
    "        elif optimizer=='ADAM':\n",
    "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n",
    "        elif optimizer=='RMSPROP':\n",
    "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n",
    "        elif optimizer=='MOM':\n",
    "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
    "        else:\n",
    "            raise ValueError('Invalid optimization algorithm')\n",
    "    \n",
    "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n",
    "        \n",
    "    # Apply gradients.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "  \n",
    "    # Add histograms for trainable variables.\n",
    "    if log_histograms:\n",
    "        for var in tf.trainable_variables():\n",
    "            tf.summary.histogram(var.op.name, var)\n",
    "   \n",
    "    # Add histograms for gradients.\n",
    "    if log_histograms:\n",
    "        for grad, var in grads:\n",
    "            if grad is not None:\n",
    "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "  \n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        moving_average_decay, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "  \n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "  \n",
    "    return train_op\n",
    "\n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y  \n",
    "\n",
    "def crop(image, random_crop, image_size):\n",
    "    if image.shape[1]>image_size:\n",
    "        sz1 = int(image.shape[1]//2)\n",
    "        sz2 = int(image_size//2)\n",
    "        if random_crop:\n",
    "            diff = sz1-sz2\n",
    "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n",
    "        else:\n",
    "            (h, v) = (0,0)\n",
    "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n",
    "    return image\n",
    "  \n",
    "def flip(image, random_flip):\n",
    "    if random_flip and np.random.choice([True, False]):\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "def to_rgb(img):\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((160, 160, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
    "    return ret\n",
    "  \n",
    "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n",
    "    nrof_samples = len(image_paths)\n",
    "    images = np.zeros((nrof_samples, image_size, image_size, 3))\n",
    "    for i in range(nrof_samples):\n",
    "        img = imageio.imread(image_paths[i])\n",
    "        if img.ndim == 2:\n",
    "            img = to_rgb(img)\n",
    "        if do_prewhiten:\n",
    "            img = prewhiten(img)\n",
    "        img = crop(img, do_random_crop, image_size)\n",
    "        img = flip(img, do_random_flip)\n",
    "        img= st.resize(img, (160, 160))\n",
    "        images[i,:,:,:] = img\n",
    "    return images\n",
    "\n",
    "def get_label_batch(label_data, batch_size, batch_index):\n",
    "    nrof_examples = np.size(label_data, 0)\n",
    "    j = batch_index*batch_size % nrof_examples\n",
    "    if j+batch_size<=nrof_examples:\n",
    "        batch = label_data[j:j+batch_size]\n",
    "    else:\n",
    "        x1 = label_data[j:nrof_examples]\n",
    "        x2 = label_data[0:nrof_examples-j]\n",
    "        batch = np.vstack([x1,x2])\n",
    "    batch_int = batch.astype(np.int64)\n",
    "    return batch_int\n",
    "\n",
    "def get_batch(image_data, batch_size, batch_index):\n",
    "    nrof_examples = np.size(image_data, 0)\n",
    "    j = batch_index*batch_size % nrof_examples\n",
    "    if j+batch_size<=nrof_examples:\n",
    "        batch = image_data[j:j+batch_size,:,:,:]\n",
    "    else:\n",
    "        x1 = image_data[j:nrof_examples,:,:,:]\n",
    "        x2 = image_data[0:nrof_examples-j,:,:,:]\n",
    "        batch = np.vstack([x1,x2])\n",
    "    batch_float = batch.astype(np.float32)\n",
    "    return batch_float\n",
    "\n",
    "def get_triplet_batch(triplets, batch_index, batch_size):\n",
    "    ax, px, nx = triplets\n",
    "    a = get_batch(ax, int(batch_size/3), batch_index)\n",
    "    p = get_batch(px, int(batch_size/3), batch_index)\n",
    "    n = get_batch(nx, int(batch_size/3), batch_index)\n",
    "    batch = np.vstack([a, p, n])\n",
    "    return batch\n",
    "\n",
    "def get_learning_rate_from_file(filename, epoch):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split('#', 1)[0]\n",
    "            if line:\n",
    "                par = line.strip().split(':')\n",
    "                e = int(par[0])\n",
    "                lr = float(par[1])\n",
    "                if e <= epoch:\n",
    "                    learning_rate = lr\n",
    "                else:\n",
    "                    return learning_rate\n",
    "\n",
    "class ImageClass():\n",
    "    \"Stores the paths to images for a given class\"\n",
    "    def __init__(self, name, image_paths):\n",
    "        self.name = name\n",
    "        self.image_paths = image_paths\n",
    "  \n",
    "    def __str__(self):\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "  \n",
    "    def get_dataset(paths, has_class_directories=True):\n",
    "        dataset = []\n",
    "        for path in paths.split(':'):\n",
    "            path_exp = os.path.expanduser(path)\n",
    "            classes = os.listdir(path_exp)\n",
    "            classes.sort()\n",
    "            nrof_classes = len(classes)\n",
    "            for i in range(nrof_classes):\n",
    "                class_name = classes[i]\n",
    "                facedir = os.path.join(path_exp, class_name)\n",
    "                image_paths = get_image_paths(facedir)\n",
    "                dataset.append(ImageClass(class_name, image_paths))\n",
    "  \n",
    "        return dataset\n",
    "\n",
    "def get_image_paths(facedir):\n",
    "    image_paths = []\n",
    "    if os.path.isdir(facedir):\n",
    "        images = os.listdir(facedir)\n",
    "        image_paths = [os.path.join(facedir,img) for img in images]\n",
    "    return image_paths\n",
    "  \n",
    "def split_dataset(dataset, split_ratio, mode):\n",
    "    if mode=='SPLIT_CLASSES':\n",
    "        nrof_classes = len(dataset)\n",
    "        class_indices = np.arange(nrof_classes)\n",
    "        np.random.shuffle(class_indices)\n",
    "        split = int(round(nrof_classes*split_ratio))\n",
    "        train_set = [dataset[i] for i in class_indices[0:split]]\n",
    "        test_set = [dataset[i] for i in class_indices[split:-1]]\n",
    "    elif mode=='SPLIT_IMAGES':\n",
    "        train_set = []\n",
    "        test_set = []\n",
    "        min_nrof_images = 2\n",
    "        for cls in dataset:\n",
    "            paths = cls.image_paths\n",
    "            np.random.shuffle(paths)\n",
    "            split = int(round(len(paths)*split_ratio))\n",
    "            if split<min_nrof_images:\n",
    "                continue  # Not enough images for test set. Skip class...\n",
    "            train_set.append(ImageClass(cls.name, paths[0:split]))\n",
    "            test_set.append(ImageClass(cls.name, paths[split:-1]))\n",
    "    else:\n",
    "        raise ValueError('Invalid train/test split mode \"%s\"' % mode)\n",
    "    return train_set, test_set\n",
    "\n",
    "def load_model(model):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "    \n",
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    \n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff),1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        \n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "          \n",
    "        tpr = np.mean(tprs,0)\n",
    "        fpr = np.mean(fprs,0)\n",
    "    return tpr, fpr, accuracy\n",
    "\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "  \n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
    "    acc = float(tp+tn)/dist.size\n",
    "    return tpr, fpr, acc\n",
    "\n",
    "\n",
    "  \n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "    \n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff),1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "      \n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
    "        if np.max(far_train)>=far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "    \n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
    "  \n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "\n",
    "\n",
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "    return val, far\n",
    "\n",
    "def store_revision_info(src_path, output_dir, arg_string):\n",
    "  \n",
    "    # Get git hash\n",
    "    gitproc = Popen(['git', 'rev-parse', 'HEAD'], stdout = PIPE, cwd=src_path)\n",
    "    (stdout, _) = gitproc.communicate()\n",
    "    git_hash = stdout.strip()\n",
    "  \n",
    "    # Get local changes\n",
    "    gitproc = Popen(['git', 'diff', 'HEAD'], stdout = PIPE, cwd=src_path)\n",
    "    (stdout, _) = gitproc.communicate()\n",
    "    git_diff = stdout.strip()\n",
    "    \n",
    "    # Store a text file in the log directory\n",
    "    rev_info_filename = os.path.join(output_dir, 'revision_info.txt')\n",
    "    with open(rev_info_filename, \"w\") as text_file:\n",
    "        text_file.write('arguments: %s\\n--------------------\\n' % arg_string)\n",
    "        text_file.write('git hash: %s\\n--------------------\\n' % git_hash)\n",
    "        text_file.write('%s' % git_diff)\n",
    "\n",
    "def list_variables(filename):\n",
    "    reader = training.NewCheckpointReader(filename)\n",
    "    variable_map = reader.get_variable_to_shape_map()\n",
    "    names = sorted(variable_map.keys())\n",
    "    return names\n",
    "\n",
    "def put_images_on_grid(images, shape=(16,8)):\n",
    "    nrof_images = images.shape[0]\n",
    "    img_size = images.shape[1]\n",
    "    bw = 3\n",
    "    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\n",
    "    for i in range(shape[1]):\n",
    "        x_start = i*(img_size+bw)+bw\n",
    "        for j in range(shape[0]):\n",
    "            img_index = i*shape[0]+j\n",
    "            if img_index>=nrof_images:\n",
    "                break\n",
    "            y_start = j*(img_size+bw)+bw\n",
    "            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\n",
    "        if img_index>=nrof_images:\n",
    "            break\n",
    "    return img\n",
    "\n",
    "def write_arguments_to_file(args, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for key, value in vars(args).iteritems():\n",
    "            f.write('%s: %s\\n' % (key, str(value)))\n",
    "import skimage.transform as st\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\PHYTHON\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Loading feature extraction model\n",
      "Model filename: ./model/20170511-185253.pb\n",
      "WARNING:tensorflow:From <ipython-input-1-d680eac3e4a5>:1269: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import facenet\n",
    "#import detect_face\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "starttime=time.time()\n",
    "img_path='E:\\photos\\surya\\WIN_20200201_121054.jpg'\n",
    "modeldir = './model/20170511-185253.pb'\n",
    "classifier_filename = './class/classifier.pkl'\n",
    "npy='./npy'\n",
    "train_img=\"./train_img\"\n",
    "\n",
    "with tf.compat.v1.Graph().as_default():\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    sess = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = create_mtcnn(sess, npy)\n",
    "\n",
    "        minsize = 20  # minimum size of face\n",
    "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "        factor = 0.709  # scale factor\n",
    "        margin = 44\n",
    "        frame_interval = 3\n",
    "        batch_size = 1000\n",
    "        image_size = 182\n",
    "        input_image_size = 160\n",
    "        \n",
    "        HumanNames = os.listdir(train_img)\n",
    "        HumanNames.sort()\n",
    "\n",
    "        print('Loading feature extraction model')\n",
    "        load_model(modeldir)\n",
    "\n",
    "        images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "\n",
    "        classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "        with open(classifier_filename_exp, 'rb') as infile:\n",
    "            (model, class_names) = pickle.load(infile)\n",
    "\n",
    "        # video_capture = cv2.VideoCapture(\"akshay_mov.mp4\")\n",
    "        c = 0\n",
    "\n",
    "endtime=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28401469 0.23790362 0.47808168]]\n",
      "unknown\n",
      "[[0.14488718 0.16665954 0.68845328]]\n",
      "surya\n",
      "[[0.09052739 0.27425925 0.63521336]]\n",
      "surya\n",
      "[[0.14142451 0.20237472 0.65620077]]\n",
      "surya\n",
      "[[0.09372006 0.25933575 0.64694419]]\n",
      "surya\n",
      "[[0.08949347 0.12696823 0.7835383 ]]\n",
      "surya\n",
      "[[0.05250109 0.21757027 0.72992864]]\n",
      "surya\n",
      "[[0.09420612 0.20663371 0.69916017]]\n",
      "surya\n",
      "[[0.06651208 0.19103509 0.74245283]]\n",
      "surya\n",
      "[[0.05398084 0.07055611 0.87546305]]\n",
      "surya\n",
      "[[0.15059251 0.32782228 0.52158521]]\n",
      "surya\n",
      "[[0.10139662 0.39902719 0.49957618]]\n",
      "unknown\n",
      "[[0.07621762 0.32576828 0.5980141 ]]\n",
      "surya\n",
      "[[0.05110587 0.19637028 0.75252386]]\n",
      "surya\n",
      "[[0.15448644 0.12597034 0.71954322]]\n",
      "surya\n",
      "[[0.03714695 0.18200324 0.78084981]]\n",
      "surya\n",
      "[[0.05505359 0.18944255 0.75550387]]\n",
      "surya\n",
      "[[0.09560835 0.13801626 0.76637539]]\n",
      "surya\n",
      "[[0.07778579 0.27403562 0.64817859]]\n",
      "surya\n",
      "[[0.07182716 0.22619175 0.70198109]]\n",
      "surya\n",
      "[[0.09250198 0.30396897 0.60352905]]\n",
      "surya\n",
      "[[0.06380442 0.16337788 0.77281771]]\n",
      "surya\n",
      "[[0.06409836 0.17761497 0.75828666]]\n",
      "surya\n",
      "[[0.03536827 0.11826612 0.84636561]]\n",
      "surya\n",
      "[[0.02626301 0.0983616  0.87537539]]\n",
      "surya\n",
      "[[0.03393026 0.1452097  0.82086004]]\n",
      "surya\n",
      "[[0.04298163 0.10874154 0.84827683]]\n",
      "surya\n",
      "[[0.04413393 0.21333401 0.74253206]]\n",
      "surya\n",
      "[[0.04856342 0.21852504 0.73291155]]\n",
      "surya\n",
      "[[0.07204278 0.24291338 0.68504384]]\n",
      "surya\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    starttime=time.time()\n",
    "    \n",
    "    with tf.compat.v1.Graph().as_default():\n",
    "       \n",
    "\n",
    "      #  print('Start Recognition!')\n",
    "        prevTime = 0\n",
    "        # ret, frame = video_capture.read()\n",
    "        #frame = imageio.imread(img_path)\n",
    "        ret,frame=cap.read()\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)    #resize frame (optional)\n",
    "\n",
    "        curTime = time.time()+1    # calc fps\n",
    "        timeF = frame_interval\n",
    "\n",
    "        if (c % timeF == 0):\n",
    "            find_results = []\n",
    "\n",
    "            if frame.ndim == 2:\n",
    "                frame = to_rgb(frame)\n",
    "            frame = frame[:, :, 0:3]\n",
    "            bounding_boxes, _ = detect_face(frame, minsize, pnet, rnet, onet, threshold, factor)\n",
    "            nrof_faces = bounding_boxes.shape[0]\n",
    "           # print('Face Detected: %d' % nrof_faces)\n",
    "\n",
    "            if nrof_faces > 0:\n",
    "                det = bounding_boxes[:, 0:4]\n",
    "                img_size = np.asarray(frame.shape)[0:2]\n",
    "\n",
    "                cropped = []\n",
    "                scaled = []\n",
    "                scaled_reshape = []\n",
    "                bb = np.zeros((nrof_faces,4), dtype=np.int32)\n",
    "\n",
    "                for i in range(nrof_faces):\n",
    "                    emb_array = np.zeros((1, embedding_size))\n",
    "\n",
    "                    bb[i][0] = det[i][0]\n",
    "                    bb[i][1] = det[i][1]\n",
    "                    bb[i][2] = det[i][2]\n",
    "                    bb[i][3] = det[i][3]\n",
    "\n",
    "                    # inner exception\n",
    "                    if bb[i][0] <= 0 or bb[i][1] <= 0 or bb[i][2] >= len(frame[0]) or bb[i][3] >= len(frame):\n",
    "                        print('face is too close')\n",
    "                        continue\n",
    "\n",
    "                    cropped.append(frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :])\n",
    "                    cropped[i] = flip(cropped[i], False)\n",
    "                    scaled.append(numpy.array(Image.fromarray(cropped[i]).resize(size=(image_size, image_size))))\n",
    "                   # numpy.array(Image.fromarray(cropped[i]).resize(size=(image_size, image_size)))\n",
    "                    scaled[i] = cv2.resize(scaled[i], (input_image_size,input_image_size),\n",
    "                                           interpolation=cv2.INTER_CUBIC)\n",
    "                    scaled[i] = prewhiten(scaled[i])\n",
    "                    scaled_reshape.append(scaled[i].reshape(-1,input_image_size,input_image_size,3))\n",
    "                    feed_dict = {images_placeholder: scaled_reshape[i], phase_train_placeholder: False}\n",
    "                    emb_array[0, :] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "                    predictions = model.predict_proba(emb_array)\n",
    "                    print(predictions)\n",
    "                    best_class_indices = np.argmax(predictions, axis=1)\n",
    "                    # print(best_class_indices)\n",
    "                    #best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "                   # print(best_class_probabilities[0])\n",
    "                    #cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)    #boxing face\n",
    "\n",
    "                    #plot result idx under box\n",
    "                    text_x = bb[i][0]\n",
    "                    text_y = bb[i][3] + 20\n",
    "                   # print('Result Indices: ', best_class_indices[0])\n",
    "                   # print(HumanNames)\n",
    "                    for H_i in HumanNames:\n",
    "                        # print(H_i)\n",
    "                        if HumanNames[best_class_indices[0]] == H_i:\n",
    "                            result_names = HumanNames[best_class_indices[0]]\n",
    "                            if np.amax(predictions)>=0.50:\n",
    "                                print(result_names)\n",
    "                                \n",
    "                                \n",
    "                                login_data={\n",
    "                                            'name': result_names,\n",
    "                                            'branch': 'cam1'\n",
    "                                            }\n",
    "\n",
    "\n",
    "                                with requests.session() as s:\n",
    "                                    url=\"http://surya.scienceontheweb.net/update.php\"\n",
    "                                    r=s.get(url,headers=headers)\n",
    "                                    #soup=BeautifulSoup(r.content,'html5lib')\n",
    "                                    #soup.find('input',attrs={'name':'name'})['koushik']\n",
    "                                    r=s.post(url,data=login_data,headers=headers)\n",
    "                                    #print(r.content)\n",
    "                                    #mycursor.execute(\"UPDATE `college` SET `place`='cam1' WHERE name='\"+result_names+\"';\")\n",
    "                                    #mycursor.execute(\"commit;\")\n",
    "                            else:\n",
    "                                print('unknown')\n",
    "                        #    cv2.putText(frame, result_names, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        #                1, (0, 0, 255), thickness=1, lineType=2)\n",
    "            else:\n",
    "                pass\n",
    "                #print('Unable to align')\n",
    "            endtime=time.time()\n",
    "            #print(endtime-starttime)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocess import preprocesses\n",
    "input_datadir = './train_img'\n",
    "output_datadir = './pre_img'\n",
    "obj=preprocesses(input_datadir,output_datadir)\n",
    "nrof_images_total,nrof_successfully_aligned=obj.collect_data()\n",
    "print('Total number of images: %d' % nrof_images_total)\n",
    "print('Number of successfully aligned images: %d' % nrof_successfully_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "datadir = './pre_img'\n",
    "modeldir = './model/20170511-185253.pb'\n",
    "classifier_filename = './class/classifier.pkl'\n",
    "print (\"Training Start\")\n",
    "obj=training(datadir,modeldir,classifier_filename)\n",
    "get_file=obj.main_train()\n",
    "print('Saved classifier model to file \"%s\"' % get_file)\n",
    "sys.exit(\"All Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
